Sistema de An√°lisis de Emociones y Biose√±ales en Respuesta a M√∫sica Generativa

Este proyecto forma parte de mi tesis doctoral, donde investigo la correlaci√≥n entre las respuestas fisiol√≥gicas y emocionales de una persona y los est√≠mulos musicales generados por un modelo de inteligencia artificial.

El sistema completo se ejecuta en un entorno h√≠brido de Windows 11 con WSL2 y utiliza un dispositivo ESP32 para la captura de datos biom√©tricos.

‚öôÔ∏è Componentes del Sistema
El proyecto se compone de varios scripts que trabajan de forma sincronizada:

Componente	Entorno de Ejecuci√≥n	Descripci√≥n
script_global.sh	WSL2 (Bash)	Es el orquestador principal. Monitorea la carpeta de m√∫sica generada, coordina el inicio y final de la grabaci√≥n de v√≠deo y biomedidas, y lanza el an√°lisis de emociones.
capture_10s.py	Windows 11 (Python)	Controla la c√°mara y la reproducci√≥n del audio. Inicia una pre-captura para estabilizar el enfoque, graba los frames a 30 FPS en alta calidad (PNG) y crea un archivo de se√±al para sincronizarse con WSL2.
receptor_controlado.py	WSL2 (Python)	Un cliente MQTT que se ejecuta en segundo plano. Recibe los comandos START y STOP y los datos biom√©tricos del ESP32, guardando la informaci√≥n en un archivo CSV.
analizar_emocion.py	WSL2 (Python)	Procesa los frames de v√≠deo capturados por la c√°mara y utiliza DeepFace para detectar y clasificar las emociones faciales del sujeto de prueba.
final_ESP32.ino	Arduino (ESP32)	El firmware del ESP32. Utiliza sensores para medir la biose√±al (ritmo card√≠aco, SpO2, respuesta galv√°nica de la piel) y publica los datos v√≠a MQTT.

Exportar a Hojas de c√°lculo
üöÄ Flujo de Trabajo
El proceso de captura y an√°lisis se automatiza por completo de la siguiente manera:

Generaci√≥n de m√∫sica: El modelo generativo ace-step (no incluido en este repositorio) produce un archivo de audio (.wav) en una carpeta espec√≠fica de WSL2.

Detecci√≥n y Sincronizaci√≥n: script_global.sh detecta el nuevo archivo y lanza capture_10s.py en Windows. El script de Windows inicia la c√°mara y, tras un breve periodo de estabilizaci√≥n, crea un archivo de se√±al.

Grabaci√≥n Sincronizada: script_global.sh detecta el archivo de se√±al, env√≠a el comando START por MQTT al receptor_controlado.py y a la vez, capture_10s.py comienza a grabar frames y reproducir la m√∫sica.

Finalizaci√≥n: Al terminar la m√∫sica, el script de Bash env√≠a el comando STOP a trav√©s de MQTT, deteniendo la grabaci√≥n de biomedidas.

An√°lisis: Finalmente, analizar_emocion.py procesa los frames de v√≠deo capturados, generando un archivo CSV con el an√°lisis emocional para su posterior correlaci√≥n con los datos biom√©tricos.

üõ†Ô∏è Requisitos del Sistema
Sistema operativo: Windows 11

Entorno de virtualizaci√≥n: WSL2

Hardware: PC con al menos 32 GB de RAM y una RTX 4050 o superior.

Dispositivos: ESP32 con los sensores correspondientes y una c√°mara USB.

Software:

Python 3.12 (en ambos entornos)

Docker Desktop (para el broker MQTT)

IDE de Arduino

Librer√≠as de Python: paho-mqtt, pygame, mutagen, deepface, opencv-python, pandas.
